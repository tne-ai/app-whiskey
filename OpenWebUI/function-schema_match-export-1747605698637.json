[{"id":"schema_match","user_id":"828dc576-91de-457b-b9bc-b3eaa0118bdf","name":"schema_match","type":"pipe","content":"import openai\n\nimport google.generativeai as genai\nimport psycopg2\nfrom pydantic import BaseModel, Field\nfrom psycopg2.extras import RealDictCursor\n\nimport os\nimport json\nimport re\nimport uuid\n\n\n# --- Configuration Class ---\nclass Pipe:\n    class Valves(BaseModel):\n        MODEL_ID: str = Field(default=\"gemma-3-27b-it\")\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    async def pipe(self, body: dict):\n\n        async def get_table_columns(cur, table_name):\n            cur.execute(\n                f\"\"\"\n                SELECT column_name\n                FROM information_schema.columns\n                WHERE table_name = %s AND table_schema = 'public'\n                ORDER BY ordinal_position\n            \"\"\",\n                (table_name,),\n            )\n            return [row[\"column_name\"] for row in cur.fetchall()]\n\n        async def insert_into_postgres(\n            data: list, entry_type: str, arrival_doc_id: str, site_id: str\n        ) -> any:\n            print(f\"INSIDE OF FUNC: {data}\")\n\n            required_vars = {\n                \"VITE_DB_USER\": os.getenv(\"VITE_DB_USER\"),\n                \"VITE_DB_PASSWORD\": os.getenv(\"VITE_DB_PASSWORD\"),\n            }\n            missing = [k for k, v in required_vars.items() if not v]\n            if missing:\n                raise EnvironmentError(\n                    f\"Missing environment variables: {', '.join(missing)}\"\n                )\n\n            supabase_host = \"aws-0-eu-central-1.pooler.supabase.com\"\n            supabase_db = \"postgres\"\n            supabase_user = required_vars[VITE_DB_USER]\n            supabase_password = required_vars[VITE_DB_PASSWORD]\n            supabase_port = 6543\n\n            conn = psycopg2.connect(\n                host=supabase_host,\n                port=supabase_port,\n                dbname=supabase_db,\n                user=supabase_user,\n                password=supabase_password,\n            )\n\n            cur = conn.cursor(cursor_factory=RealDictCursor)\n            print(f\"Connected to DB\")\n\n            table_map = {\n                \"materials\": \"i_materials\",\n                \"logistics\": \"i_logistics\",\n                \"resource_removal\": \"i_resource_removal\",\n            }\n\n            table = table_map.get(entry_type, \"inferred_table\")\n\n            columns = await get_table_columns(cur, table)\n\n            for item in data:\n                arrival_doc_item_name = item.get(\"arrival_doc_item_name\")\n                if not arrival_doc_item_name:\n                    print(f\"Skipping item with no arrival_doc_item_name: {item}\")\n                    continue\n                if not arrival_doc_item_name:\n                    print(f\"Skipping item without arrival_doc_item_name: {item}\")\n                    continue\n\n                # --- Query to enrich item from l_item_details ---\n                cur.execute(\n                    \"\"\"\n                    SELECT submaterial_id, weight_kg, volume_m3\n                    FROM l_item_details\n                    WHERE item_name = %s\n                    LIMIT 1\n                    \"\"\",\n                    (arrival_doc_item_name,),\n                )\n                match = cur.fetchone()\n\n                if match:\n                    item[\"submaterial_id\"] = match[\"submaterial_id\"]\n                    item[\"weight_kg\"] = match[\"weight_kg\"]\n                    item[\"volume_m3\"] = match[\"volume_m3\"]\n                else:\n                    print(f\"No match found for item name: {arrival_doc_item_name}\")\n                    item[\"submaterial_id\"] = None\n                    item[\"weight_kg\"] = None\n                    item[\"volume_m3\"] = None\n\n                item[\"arrival_doc_id\"] = arrival_doc_id\n                item[\"site_id\"] = site_id\n                item[\"material_entry_id\"] = str(uuid.uuid4())\n\n                row_values = [item.get(col, None) for col in columns]\n\n                # Prepare INSERT\n                placeholders = \", \".join([\"%s\"] * len(columns))\n                column_names = \", \".join(columns)\n                insert_query = f\"\"\"\n                    INSERT INTO {table} ({column_names})\n                    VALUES ({placeholders})\n                \"\"\"\n\n                print(\"Running query:\", insert_query)\n                print(\"With values:\", row_values)\n                cur.execute(insert_query, row_values)\n\n            conn.commit()\n            cur.close()\n            conn.close()\n            print(\"Committed and closed connection.\")\n            return None\n\n        # ----BEGIN PIPE FUNCTION------\n        print(f\"pipe:{__name__}\")\n        google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n        config = body.get(\"config\", {})\n        entry_type = config.get(\"entry_type\")\n        arrival_doc_id = config.get(\"arrival_doc_id\")\n        site_id = config.get(\"site_id\")\n        data = body[\"messages\"][-1][\"content\"]\n\n        missing_fields = []\n        if not entry_type:\n            missing_fields.append(\"entry_type\")\n        if not arrival_doc_id:\n            missing_fields.append(\"arrival_doc_id\")\n        if not site_id:\n            missing_fields.append(\"site_id\")\n        if not data:\n            missing_fields.append(\"messages[-1].content\")\n        if not google_api_key:\n            missing_fields.append(\"google_api_key\")\n\n        if missing_fields:\n            raise ValueError(f\"Missing required fields: {', '.join(missing_fields)}\")\n        schemas = {\n            \"logistics\": \"\"\"--\n                -- Name: i_logistics; Type: TABLE; Schema: public; Owner: postgres\n                --\n                \n                CREATE TABLE public.i_logistics (\n                    logistics_id uuid DEFAULT gen_random_uuid() NOT NULL,\n                    site_id uuid NOT NULL,\n                    submaterial_id uuid NOT NULL,\n                    supplier_id uuid,\n                    total_material_weight_kg numeric(12,2),\n                    delivery_distance_km integer,\n                    delivery_date date,\n                    delivery_vehicle_type_id uuid,\n                    delivery_notes text\n                );\n                \"\"\",\n            \"materials\": \"\"\"--\n                -- Name: i_materials; Type: TABLE; Schema: public; Owner: postgres\n                --\n                \n                CREATE TABLE public.i_materials (\n                    material_entry_id uuid default gen_random_uuid() not null\n                    primary key,\n                    site_id uuid not null\n                    references public.i_sites,\n                    submaterial_id uuid not null\n                    references public.l_submaterials,\n                    quantity numeric(12, 2) not null,\n                    unit_id uuid\n                    references public.l_units,\n                    weight_kg numeric(12, 2),\n                    volume_m3 numeric(12, 2),\n                    cost_per_unit numeric(12, 2),\n                    total_cost numeric(12, 2),\n                    supplier_id uuid\n                    references public.l_suppliers,\n                    delivery_date date,\n                    stage_id uuid\n                    references public.i_stages,\n                    notes text,\n                    item_id uuid,\n                    arrival_doc_item_name varchar,\n                    arrival_doc_id uuid,\n                    is_valid boolean default false,\n                    default_waste_pct numeric(5, 2)\n                    );\"\"\",\n            \"resource_removal\": \"\"\"--\n                -- Name: i_resource_removal; Type: TABLE; Schema: public; Owner: postgres\n                --\n                \n                CREATE TABLE public.i_resource_removal (\n                    removal_id uuid DEFAULT gen_random_uuid() NOT NULL,\n                    site_id uuid NOT NULL,\n                    submaterial_id uuid NOT NULL,\n                    waste_weight_kg numeric(12,2),\n                    waste_volume_m3 numeric(12,2),\n                    removal_distance_km integer,\n                    removal_date date,\n                    disposal_method_id uuid,\n                    disposal_facility_id uuid,\n                    removal_cost numeric(12,2),\n                    removal_notes text\n                );\n            \"\"\",\n        }\n        schema = schemas.get(entry_type)\n        if not schema:\n            return f\"Error: unknown entry type '{entry_type}'\"\n\n        genai.configure(api_key=google_api_key)\n        model = genai.GenerativeModel(\"gemma-3-27b-it\")\n\n        prompt = f\"\"\"\n            You are an expert in data management. Your job is to identify line item data and extract quantity, name of the item, and any other relevant information that fits the schema strictly.\n            return a JSON list of structured data objects that conform to the schema. Skip any fields that are not included in the data.\n        \n            Schema:\\n{schema}\n        \n            Raw Data:\\n{data}\n        \n            Return only valid JSON in your response.\n        \"\"\"\n        try:\n            response = model.generate_content(prompt)\n            structured_output = response.text.strip()\n        except Exception as e:\n            return f\"Error calling Google Gemini API: {str(e)}\"\n        try:\n            # Remove surrounding triple backticks and \"json\" if present\n            cleaned_output = re.sub(\n                r\"^```json|```$\", \"\", structured_output.strip(), flags=re.IGNORECASE\n            ).strip(\"` \\n\")\n\n            parsed_data = json.loads(cleaned_output)\n\n            if not isinstance(parsed_data, list):\n                raise ValueError(\"Expected a list of JSON objects\")\n\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"LLM returned invalid JSON: {e}\")\n\n        await insert_into_postgres(parsed_data, entry_type, arrival_doc_id, site_id)\n        return parsed_data\n","meta":{"description":"takes material input line items and adds to sql database.","manifest":{}},"is_active":true,"is_global":false,"updated_at":1747605694,"created_at":1747605690}]